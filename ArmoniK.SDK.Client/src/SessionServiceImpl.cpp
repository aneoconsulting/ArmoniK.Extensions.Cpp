#include "SessionServiceImpl.h"
#include "Batcher.h"
#include "armonik/sdk/client/IServiceInvocationHandler.h"
#include <armonik/client/results/ResultsClient.h>
#include <armonik/client/results_common.pb.h>
#include <armonik/client/results_service.grpc.pb.h>
#include <armonik/client/sessions/SessionsClient.h>
#include <armonik/client/sessions_service.grpc.pb.h>
#include <armonik/client/tasks/TasksClient.h>
#include <armonik/client/tasks_service.grpc.pb.h>
#include <armonik/common/exceptions/ArmoniKApiException.h>
#include <armonik/common/exceptions/ArmoniKTaskError.h>
#include <armonik/common/objects.pb.h>
#include <armonik/common/utils/GuuId.h>
#include <armonik/sdk/common/Properties.h>
#include <armonik/sdk/common/TaskPayload.h>
#include <chrono>
#include <thread>
#include <utility>
#include <vector>

namespace ArmoniK {
namespace Sdk {
namespace Client {
namespace Internal {

namespace {
/**
 * @brief Upload a large result using a stream, retrying the upload in case of error
 * @param pool The channel pool to use to perform the requests
 * @param session Id of the session where the result has been created
 * @param result_id Id of the result to upload
 * @param data Content of the result to upload
 * @param data_max_chunk_size Size of the chunks to upload the data
 * @param logger Logger
 */
void upload_large_result(ArmoniK::Sdk::Client::Internal::ChannelPool &pool, std::string session, std::string result_id,
                         absl::string_view data, std::size_t data_chunk_max_size,
                         armonik::api::common::logger::ILogger &logger) {

  std::exception_ptr eptr;

  // Retry the upload at most 3 times
  const int max_retry = 3;
  for (int retry = 0; retry < max_retry; ++retry) {
    eptr = nullptr;
    auto remaining_data = data;

    // If retry is available (not the last iteration), add prefix to the logs to indicate the upload will be retried
    // even though there was an error, and log errors as warnings
    bool can_retry = retry + 1 < max_retry;
    const char *retry_notif = can_retry ? "Upload will be RETRIED: " : "";
    auto loglevel =
        can_retry ? armonik::api::common::logger::Level::Warning : armonik::api::common::logger::Level::Error;

    try {
      auto channel = pool.GetChannel();

      grpc::ClientContext context{};
      armonik::api::grpc::v1::results::UploadResultDataRequest request{};
      armonik::api::grpc::v1::results::UploadResultDataResponse response{};

      auto client = armonik::api::grpc::v1::results::Results::NewStub(channel.channel);
      auto stream = client->UploadResultData(&context, &response);

      // Send message header with the result identifier
      request.mutable_id()->set_session_id(session);
      request.mutable_id()->set_result_id(result_id);
      stream->Write(request);
      request.clear_id();

      // Chunk the content to send it in multiple messages
      while (!remaining_data.empty()) {
        auto chunk = remaining_data.substr(0, data_chunk_max_size);
        request.mutable_data_chunk()->assign(chunk.data(), chunk.size());
        if (!stream->Write(request)) {
          throw armonik::api::common::exceptions::ArmoniKApiException("Unable to continue upload result " + result_id);
        }
        remaining_data = remaining_data.substr(chunk.size());
      }

      if (!stream->WritesDone()) {
        throw armonik::api::common::exceptions::ArmoniKApiException("Unable to upload result " + result_id);
      }
      auto status = stream->Finish();
      if (!status.ok()) {
        throw armonik::api::common::exceptions::ArmoniKApiException("Unable to finish upload result " + result_id +
                                                                    ": " + status.error_message());
      }

      // If the uploaded size is different than the actual data size, upload must be retried
      // Otherwise, we are good to go.
      if (response.result().size() == std::int64_t(data.size())) {
        break;
      }

      // If the uploaded size is different, delete the uploaded data from the object storage
      try {
        pool.WithChannel([&](auto channel) {
          armonik::api::client::ResultsClient(armonik::api::grpc::v1::results::Results::NewStub(channel))
              .delete_results_data(session, {std::move(*response.mutable_result()->mutable_result_id())});
        });
      } catch (const std::exception &e) {
        logger.warning("Unable to clean data for " + result_id + ": " + e.what());
      } catch (...) {
        logger.warning("Unable to clean data for " + result_id + ": unknown exception");
      }

      std::stringstream ss;
      ss << retry_notif << "Corrupted result " << result_id << " upload: mismatched between client size ("
         << data.size() << " B) and server size (" << response.result().size() << ")";

      throw std::make_exception_ptr(armonik::api::common::exceptions::ArmoniKApiException(ss.str()));
    } catch (const std::exception &e) {
      logger.log(loglevel, std::string(retry_notif) + "Failed to upload result " + result_id + ": " + e.what());
      eptr = std::current_exception();
    } catch (...) {
      logger.log(loglevel, std::string(retry_notif) + "Failed to upload result " + result_id + ": unknown exception");
      eptr = std::current_exception();
    }
  }

  if (eptr) {
    std::rethrow_exception(eptr);
  }
}
} // namespace

const std::string &SessionServiceImpl::getSession() const { return session; }

[[maybe_unused]] std::vector<std::string>
SessionServiceImpl::Submit(const std::vector<Common::TaskPayload> &task_requests,
                           std::shared_ptr<IServiceInvocationHandler> handler,
                           const Common::TaskOptions &task_options) {

  const std::size_t message_overhead = 128;
  std::size_t data_chunk_max_size =
      override_message_size_ ? override_message_size_ : channel_pool.WithChannel([](auto channel) {
        return armonik::api::client::ResultsClient(armonik::api::grpc::v1::results::Results::NewStub(channel))
            .get_service_configuration()
            .data_chunk_max_size;
      });

  // Number of bytes to be sent in the next CreateResult request
  std::size_t data_batched = 0;

  std::vector<std::string> input_result_ids(task_requests.size());
  std::vector<std::string> output_result_ids(task_requests.size());
  std::vector<std::string> task_ids(task_requests.size());

  ThreadPool::JoinSet join_set(thread_pool_);

  // Batch Result metadata creation (for outputs and large inputs) and upload inputs
  Batcher<std::pair<std::size_t, bool>> create_metadata_and_upload_batcher(
      submit_batch_size_, [&](std::vector<std::pair<std::size_t, bool>> &&batch) {
        join_set.Spawn([&, batch = std::move(batch)]() {
          std::vector<std::string> names(batch.size());
          for (std::size_t j = 0; j < batch.size(); ++j) {
            int i = batch[j].first;
            bool is_output = batch[j].second;

            names[j] = (is_output ? "output-" : "input-") + std::to_string(i);
          }

          auto reply = channel_pool.WithChannel([&](auto channel) {
            return armonik::api::client::ResultsClient(armonik::api::grpc::v1::results::Results::NewStub(channel))
                .create_results_metadata(session, names);
          });

          // threadsafe as the index is unique among all batches
          for (std::size_t j = 0; j < batch.size(); ++j) {
            std::size_t i = batch[j].first;
            bool is_output = batch[j].second;

            if (is_output) {
              output_result_ids[i] = std::move(reply[names[j]]);
            } else {
              input_result_ids[i] = std::move(reply[names[j]]);

              // Upload result using stream
              join_set.Spawn([&, i]() {
                upload_large_result(channel_pool, session, input_result_ids[i], task_requests[i].Serialize(),
                                    data_chunk_max_size, logger_);
              });
            }
          }
        });
      });

  // Batch Result data creation (for small inputs)
  Batcher<std::size_t> create_data_batcher(submit_batch_size_, [&](std::vector<std::size_t> &&batch) {
    // Reset the number of bytes to be sent in the current batch
    data_batched = 0;

    join_set.Spawn([&, batch = std::move(batch)]() {
      std::vector<std::pair<std::string, std::string>> results(batch.size());
      for (std::size_t j = 0; j < batch.size(); ++j) {
        std::size_t i = batch[j];
        results[j] = {"input-" + std::to_string(i), task_requests[i].Serialize()};
      }
      auto reply = channel_pool.WithChannel([&](auto channel) {
        return armonik::api::client::ResultsClient(armonik::api::grpc::v1::results::Results::NewStub(channel))
            .create_results(session, results);
      });

      // threadsafe as the index is unique among all batches
      for (std::size_t j = 0; j < batch.size(); ++j) {
        std::size_t i = batch[j];
        input_result_ids[i] = std::move(reply[results[j].first]);
      }
    });
  });

  // Batch task submission
  Batcher<std::size_t> submit_batcher(submit_batch_size_, [&](std::vector<std::size_t> &&batch) {
    join_set.Spawn([&, batch = std::move(batch)]() {
      std::vector<armonik::api::common::TaskCreation> requests(batch.size());
      for (std::size_t j = 0; j < batch.size(); ++j) {
        std::size_t i = batch[j];
        auto &data_dependencies = task_requests[i].data_dependencies;
        auto &request = requests[j];

        request = armonik::api::common::TaskCreation();
        request.payload_id = input_result_ids[i];
        request.expected_output_keys.push_back(output_result_ids[i]);
        request.data_dependencies.insert(request.data_dependencies.end(), data_dependencies.begin(),
                                         data_dependencies.end());
      }

      auto reply = channel_pool.WithChannel([&](auto channel) {
        return armonik::api::client::TasksClient(armonik::api::grpc::v1::tasks::Tasks::NewStub(channel))
            .submit_tasks(session, std::move(requests), static_cast<armonik::api::grpc::v1::TaskOptions>(task_options));
      });

      // threadsafe as the index is unique among all batches
      for (std::size_t j = 0; j < batch.size(); ++j) {
        std::size_t i = batch[j];
        task_ids[i] = std::move(reply[j].task_id);

        std::stringstream ss;
        ss << "Submitted task " << task_ids[i] << " with result " << output_result_ids[i];
        logger_.debug(ss.str());
      }
    });
  });

  // Create all results
  for (std::size_t i = 0; i < task_requests.size(); ++i) {
    auto &task_request = task_requests[i];
    auto payload_size = task_request.arguments.size();

    create_metadata_and_upload_batcher.Add({i, true});
    if (payload_size + message_overhead >= data_chunk_max_size) {
      create_metadata_and_upload_batcher.Add({i, false});
    } else {
      // If current batch would be too large, send it right now
      if (data_batched + payload_size + message_overhead >= data_chunk_max_size) {
        create_data_batcher.ProcessBatch();
      }

      data_batched += payload_size + message_overhead;
      create_data_batcher.Add(i);
    }
  }

  // Ensure all results are created
  create_metadata_and_upload_batcher.ProcessBatch();
  create_data_batcher.ProcessBatch();
  join_set.Wait();

  // Submit all tasks
  for (std::size_t i = 0; i < task_requests.size(); ++i) {
    submit_batcher.Add(i);
  }

  // Ensure all tasks are actually submitted
  submit_batcher.ProcessBatch();
  join_set.Wait();

  std::lock_guard<std::mutex> lock(maps_mutex);

  for (std::size_t i = 0; i < task_requests.size(); ++i) {
    const auto &result_id = output_result_ids[i];
    const auto &task_id = task_ids[i];
    result_handlers[result_id] = handler;
    resultId_taskId[result_id] = task_id;
    taskId_resultId[task_id] = result_id;
  }

  return task_ids;
}

SessionServiceImpl::SessionServiceImpl(const Common::Properties &properties,
                                       armonik::api::common::logger::Logger &logger, const std::string &session_id)
    : taskOptions(properties.taskOptions), channel_pool(properties, logger),
      thread_pool_(properties.configuration.get_control_plane().getThreadPoolSize(), logger), logger_(logger.local()),
      wait_batch_size_(properties.configuration.get_control_plane().getWaitBatchSize()),
      submit_batch_size_(properties.configuration.get_control_plane().getSubmitBatchSize()),
      override_message_size_(properties.configuration.get_control_plane().getOverrideMessageSize()) {
  // Creates a new session
  session = session_id.empty() ? channel_pool.WithChannel([&](auto &&channel) {
    return armonik::api::client::SessionsClient(armonik::api::grpc::v1::sessions::Sessions::NewStub(channel))
        .create_session(static_cast<armonik::api::grpc::v1::TaskOptions>(properties.taskOptions),
                        {properties.taskOptions.partition_id});
  })
                               : session_id;
}

std::vector<std::string> SessionServiceImpl::Submit(const std::vector<Common::TaskPayload> &task_requests,
                                                    std::shared_ptr<IServiceInvocationHandler> handler) {
  return Submit(task_requests, std::move(handler), taskOptions);
}

void SessionServiceImpl::WaitResults(std::set<std::string> task_ids, WaitBehavior behavior,
                                     const WaitOptions &options) {
  auto function_stop = std::chrono::steady_clock::now() + std::chrono::milliseconds(options.timeout);

  bool breakOnError = behavior & WaitBehavior::BreakOnError;
  bool stopOnFirst = behavior & WaitBehavior::Any;

  std::map<std::string, armonik::api::grpc::v1::results::ResultRaw> results;
  std::atomic<bool> hasError(false);

  ThreadPool::JoinSet join_set(thread_pool_);

  {
    std::lock_guard<std::mutex> _(maps_mutex);

    if (task_ids.empty()) {
      // If the task set is empty, wait for all the results that have been submitted at the moment of the wait
      for (auto &handler : result_handlers) {
        armonik::api::grpc::v1::results::ResultRaw result{};
        result.set_result_id(handler.first);
        result.set_status(armonik::api::grpc::v1::result_status::RESULT_STATUS_NOTFOUND);
        results.emplace(handler.first, std::move(result));
      }
    } else {
      // Otherwise, wait for the results of the specified tasks only
      for (auto &tid : task_ids) {
        auto result_id = taskId_resultId.find(tid);
        if (result_id == taskId_resultId.end()) {
          logger_.warning("Task ID " + tid + " has no associated result ID, skipping wait.");
          continue;
        }

        armonik::api::grpc::v1::results::ResultRaw result{};
        result.set_result_id(result_id->second);
        result.set_status(armonik::api::grpc::v1::result_status::RESULT_STATUS_NOTFOUND);
        results.emplace(result_id->second, std::move(result));
      }
    }
  }
  size_t initial_result_size = results.size();

  // Batcher to get results in batches
  Batcher<std::string> batcher(wait_batch_size_, [&](std::vector<std::string> &&batch) {
    join_set.Spawn([&, batch = std::move(batch)]() mutable {
      armonik::api::grpc::v1::results::Filters filters{};
      for (auto &result_id : batch) {

        auto filter = filters.add_or_()->add_and_();
        filter->mutable_field()->mutable_result_raw_field()->set_field(
            armonik::api::grpc::v1::results::RESULT_RAW_ENUM_FIELD_RESULT_ID);
        filter->mutable_filter_string()->set_value(std::move(result_id));
        filter->mutable_filter_string()->set_operator_(armonik::api::grpc::v1::FILTER_STRING_OPERATOR_EQUAL);
      }

      auto response = channel_pool.WithChannel([&](auto &&channel) {
        armonik::api::client::ResultsClient resultsClient(armonik::api::grpc::v1::results::Results::NewStub(channel));
        int total = 0;
        return resultsClient.list_results(std::move(filters), total, 0, filters.or__size());
      });

      for (auto &result : response) {
        // threadsafe as the result is known to be present in the map and we have unique keys
        results[result.result_id()] = std::move(result);
      }
    });
  });

  // Wait all the specified results
  while (!results.empty()) {
    // Get all the results using batched requests
    for (auto &result : results) {
      batcher.Add(result.first);
    }
    batcher.ProcessBatch();
    join_set.Wait();

    for (auto result_it = results.begin(); result_it != results.end();) {
      auto &result = result_it->second;
      auto status = result.status();

      // reset status to not found for next iteration if not completed or aborted
      result.set_status(armonik::api::grpc::v1::result_status::RESULT_STATUS_NOTFOUND);

      // Skip results that are not yet ready
      if (status == armonik::api::grpc::v1::result_status::RESULT_STATUS_CREATED) {
        ++result_it;
        continue;
      }

      join_set.Spawn([&, result = std::move(result), status]() mutable {
        std::shared_ptr<IServiceInvocationHandler> handler{};
        std::string task_id{};

        { // Extract the handler and taskid information
          std::lock_guard<std::mutex> _(maps_mutex);
          auto handler_it = result_handlers.find(result.result_id());
          if (handler_it != result_handlers.end()) {
            handler = std::move(handler_it->second);
            result_handlers.erase(handler_it);
          }
          auto task_id_it = resultId_taskId.find(result.result_id());
          if (task_id_it != resultId_taskId.end()) {
            task_id = std::move(task_id_it->second);
            resultId_taskId.erase(task_id_it);
            taskId_resultId.erase(task_id);
          }
        }

        // function to be called upon errors
        auto handle_error = [&](const std::exception &e, const std::string &reason = {}) {
          hasError.store(true, std::memory_order_relaxed);
          std::stringstream message;
          message << "Error while handling result " << result.result_id() << " for task "
                  << (task_id.empty() ? "[UNKNOWN]" : task_id);
          if (!reason.empty()) {
            message << " : " << reason;
          }
          message << " : " << e.what();
          logger_.error(message.str());
          if (handler) {
            handler->HandleError(e, task_id);
          }
        };

        std::string payload, owner_task_id;
        switch (status) {
        // Unreachable, generate an error to avoid missing results
        case armonik::api::grpc::v1::result_status::RESULT_STATUS_CREATED:
          handle_error(armonik::api::common::exceptions::ArmoniKApiException("Unreachable: result in CREATED status"));
          break;

        // If the result is completed, we download it
        case armonik::api::grpc::v1::result_status::RESULT_STATUS_COMPLETED:
          // Download the payload
          try {
            payload = channel_pool.WithChannel([&](auto &&channel) {
              return armonik::api::client::ResultsClient(armonik::api::grpc::v1::results::Results::NewStub(channel))
                  .download_result_data(session, result.result_id());
            });
          } catch (const std::exception &e) {
            handle_error(e, "Failed to download result data");
          }

          // Call the response handler with the payload
          try {
            handler->HandleResponse(payload, task_id);
          } catch (const std::exception &e) {
            handle_error(e, "Failed to execute result handler");
          }
          break;

        // If the result is aborted, we retrieve the task error
        case armonik::api::grpc::v1::result_status::RESULT_STATUS_ABORTED:
          // The considered task is either the owner task of the result, or the original task
          owner_task_id = result.owner_task_id();
          if (result.owner_task_id().empty()) {
            owner_task_id = task_id;
          }

          if (owner_task_id.empty()) {
            handle_error(armonik::api::common::exceptions::ArmoniKApiException("Result is aborted"));
          } else {
            armonik::api::grpc::v1::TaskError error{};
            error.set_task_id(owner_task_id);

            // Retrieve the task error details
            try {
              channel_pool.WithChannel([&](auto &&channel) {
                auto task = armonik::api::client::TasksClient(armonik::api::grpc::v1::tasks::Tasks::NewStub(channel))
                                .get_task(owner_task_id);
                auto task_error = error.add_errors();
                task_error->set_detail(std::move(*task.mutable_output()->mutable_error()));
                task_error->set_task_status(task.status());
              });
            } catch (const std::exception &e) {
              error.add_errors()->set_detail(e.what());
            }
            handle_error(armonik::api::common::exceptions::ArmoniKTaskError("Result is aborted", error));
          }
          break;

        // In all other cases, we just call the handler on a generic error
        case armonik::api::grpc::v1::result_status::RESULT_STATUS_DELETED:
          handle_error(armonik::api::common::exceptions::ArmoniKApiException("Result is deleted"));
          break;
        case armonik::api::grpc::v1::result_status::RESULT_STATUS_NOTFOUND:
          handle_error(armonik::api::common::exceptions::ArmoniKApiException("Result was not found"));
          break;
        default:
          handle_error(armonik::api::common::exceptions::ArmoniKApiException("Result status is unknown"));
          break;
        }
      });

      result_it = results.erase(result_it);
    }

    join_set.Wait();

    // If we wait for any and at least one is done, or if we break on error and had an error, then return
    if ((stopOnFirst && results.size() < initial_result_size) ||
        (breakOnError && hasError.load(std::memory_order_relaxed))) {
      break;
    }
    if (std::chrono::steady_clock::now() > function_stop) {
      break;
    }
    std::this_thread::sleep_for(std::chrono::milliseconds(options.polling_ms));
  }
}

void SessionServiceImpl::CloseSession() {
  auto reply = channel_pool.WithChannel([&](const std::shared_ptr<::grpc::Channel> &channel) {
    return armonik::api::client::SessionsClient(armonik::api::grpc::v1::sessions::Sessions::NewStub(channel))
        .close_session(session);
  });
}

void SessionServiceImpl::CancelSession() {
  auto reply = channel_pool.WithChannel([&](const std::shared_ptr<::grpc::Channel> &channel) {
    return armonik::api::client::SessionsClient(armonik::api::grpc::v1::sessions::Sessions::NewStub(channel))
        .cancel_session(session);
  });
}

void SessionServiceImpl::PurgeSession() {
  auto reply = channel_pool.WithChannel([&](const std::shared_ptr<::grpc::Channel> &channel) {
    return armonik::api::client::SessionsClient(armonik::api::grpc::v1::sessions::Sessions::NewStub(channel))
        .purge_session(session);
  });
}

void SessionServiceImpl::DropSession() {
  // Clear all the maps
  {
    std::lock_guard<std::mutex> _(maps_mutex);
    taskId_resultId.clear();
    resultId_taskId.clear();
    result_handlers.clear();
  }
  // Cancel the session
  auto reply = channel_pool.WithChannel([&](const std::shared_ptr<::grpc::Channel> &channel) {
    return armonik::api::client::SessionsClient(armonik::api::grpc::v1::sessions::Sessions::NewStub(channel))
        .cancel_session(session);
  });

  // Create the result filter for result.session_id == session
  armonik::api::grpc::v1::results::Filters filters;
  armonik::api::grpc::v1::results::FilterField filter_field;
  filter_field.mutable_field()->mutable_result_raw_field()->set_field(
      armonik::api::grpc::v1::results::RESULT_RAW_ENUM_FIELD_SESSION_ID);
  filter_field.mutable_filter_string()->set_value(session);
  filter_field.mutable_filter_string()->set_operator_(armonik::api::grpc::v1::FILTER_STRING_OPERATOR_EQUAL);
  *filters.mutable_or_()->Add()->mutable_and_()->Add() = filter_field;
  int page = 0;
  const int page_size = 500;
  int total = 0;
  do {
    channel_pool.WithChannel([&](const std::shared_ptr<::grpc::Channel> &channel) {
      auto results = armonik::api::client::ResultsClient(armonik::api::grpc::v1::results::Results::NewStub(channel));
      // List results
      auto rawList = results.list_results(filters, total, page++, page_size);
      std::vector<std::string> ids;
      ids.reserve(rawList.size());
      for (auto &&raw : rawList) {
        ids.push_back(raw.result_id());
      }
      // Delete results
      try {
        results.delete_results_data(session, ids);
      } catch (const std::exception &e) {
        logger_.info(std::string("Couldn't completely destroy batch of results : ") + e.what());
      }
    });
  } while (page * page_size < total);
}

void SessionServiceImpl::CleanupTasks(std::vector<std::string> task_ids) {
  // Remove the given tasks from the maps
  {
    std::lock_guard<std::mutex> _(maps_mutex);
    for (auto &&t : task_ids) {
      auto loc = taskId_resultId.find(t);
      if (loc != taskId_resultId.end()) {
        resultId_taskId.erase(loc->second);
        result_handlers.erase(loc->second);
        taskId_resultId.erase(loc->first);
      }
    }
  }
  const size_t batch_size = 500;
  auto tasks_iterator = task_ids.begin();
  // Cancel the given tasks
  while (tasks_iterator != task_ids.end()) {
    channel_pool.WithChannel([&](const std::shared_ptr<::grpc::Channel> &channel) {
      std::vector<std::string> batched_ids;
      for (size_t i = 0; i < batch_size && tasks_iterator != task_ids.end(); ++i) {
        batched_ids.push_back(*tasks_iterator);
        tasks_iterator++;
      }
      armonik::api::client::TasksClient(armonik::api::grpc::v1::tasks::Tasks::NewStub(channel))
          .cancel_tasks(batched_ids);
    });
  }

  tasks_iterator = task_ids.begin();

  while (tasks_iterator != task_ids.end()) {
    // List batch of results from the given tasks
    auto map_results = channel_pool.WithChannel([&](const std::shared_ptr<::grpc::Channel> &channel) {
      std::vector<std::string> batched_ids;
      for (size_t i = 0; i < batch_size && tasks_iterator != task_ids.end(); ++i) {
        batched_ids.push_back(std::move(*tasks_iterator));
        tasks_iterator++;
      }
      return armonik::api::client::TasksClient(armonik::api::grpc::v1::tasks::Tasks::NewStub(channel))
          .get_result_ids(batched_ids);
    });

    // Delete results
    channel_pool.WithChannel([&](const std::shared_ptr<::grpc::Channel> &channel) {
      auto results = armonik::api::client::ResultsClient(armonik::api::grpc::v1::results::Results::NewStub(channel));
      std::vector<std::string> resultIds;
      resultIds.reserve(map_results.size());
      for (auto &&taskId_resultIds : map_results) {
        resultIds.insert(resultIds.end(), std::make_move_iterator(taskId_resultIds.second.begin()),
                         std::make_move_iterator(taskId_resultIds.second.end()));
      }
      results.delete_results_data(session, resultIds);
    });
  }
}

} // namespace Internal
} // namespace Client
} // namespace Sdk
} // namespace ArmoniK
